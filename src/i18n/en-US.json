{
  "New": "New",
  "Unnamed": "Unnamed",
  "Time": "Time",
  "Version": "Version",
  "SoftwareInfo": "Software Info",
  "License": "License",

  "Editor": {
    "Name": "Name",
    "Prompt": "Prompt",
    "Model": "Model",
    "SelectModel": "Select a model...",
    "SaySomething": "Say something...",

    "ParameterSettings": "Parameter Settings",
    "FrequencyPenalty": "Frequency Penalty",
    "PresencePenalty": "Presence Penalty",
    "MaxTokens": "Max tokens",
    "Temperature": "Temperature",
    "TopP": "Top P",

    "About": {
      "FrequencyPenalty": "Number between -2.0 and 2.0 (defaults to 0).\nPositive values penalize new tokens based on their existing frequency in the text so far,\ndecreasing the model's likelihood to repeat the same line verbatim.",
      "PresencePenalty": "Number between -2.0 and 2.0 (defaults to 0).\nPositive values penalize new tokens based on whether they appear in the text so far,\nincreasing the model's likelihood to talk about new topics.",
      "MaxTokens": "The maximum number of tokens to generate in the chat completion.",
      "Temperature": "What sampling temperature to use, between 0 and 2 (defaults to 1).\nHigher values like 0.8 will make the output more random,\nwhile lower values like 0.2 will make it more focused and deterministic.\nWe generally recommend altering this or top_p but not both.",
      "TopP": "(defaults to 1) An alternative to sampling with temperature, called nucleus sampling,\nwhere the model considers the results of the tokens with top_p probability mass.\nSo 0.1 means only the tokens comprising the top 10% probability mass are considered.\nWe generally recommend altering this or temperature but not both."
    }
  },

  "Settings": {
    "OpenAISettings": "OpenAI Settings",
    "GeneralSettings": "General Settings",
    "PrivacySettings": "Privacy Settings",

    "ApiKey": "Api Key",
    "ApiBase": "Api Endpoint",
    "OrgId": "Organization ID",
    "DefaultModel": "Default Model",
    "DefaultModelUnSet": "Unset",

    "SelectLanguage": "Select Language",
    "AllowTelemetry": "Allow Telemetry"
  },

  "Page": {
    "Editor": "Editor",
    "History": "History",
    "Settings": "Settings",
    "About": "About"
  }
}
